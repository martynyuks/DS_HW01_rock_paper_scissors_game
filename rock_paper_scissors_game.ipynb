{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Игра \"камень, ножницы, бумага\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U kaggle_environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек и функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kaggle_environments import make, evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ходы игроков представлены целочисленными константами:\n",
    "* 0 - \"камень\"\n",
    "* 1 - \"бумага\"\n",
    "* 2 - \"ножницы\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, возвращающая ход, который нужно сделать, чтобы выиграть оппонента, на основании его предполагаемого хода _opponent_action_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_to_win(opponent_action):\n",
    "    if opponent_action == 0:\n",
    "        return 1\n",
    "    elif opponent_action == 1:\n",
    "        return 2\n",
    "    elif opponent_action == 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Атрибут _observation.lastOpponentAction_ присутствует не всегда, поэтому в функциях агентов делается проверка его существования вызовом _hasattr(obj, name)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры игровых агентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# агент, выдающий всегда \"камень\"\n",
    "def rock_agent(observation, configuration):\n",
    "    return 0\n",
    "\n",
    "\n",
    "# агент, выдающий всегда \"бумага\"\n",
    "def paper_agent(observation, configuration):\n",
    "    return 1\n",
    "\n",
    "\n",
    "# агент, выдающий всегда \"ножницы\"\n",
    "def scissors_agent(observation, configuration):\n",
    "    return 2\n",
    "\n",
    "\n",
    "# агент, копирующий предыдущий ход оппонента\n",
    "def copy_agent(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        return observation.lastOpponentAction\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "\n",
    "\n",
    "# агент, предполагающий, что оппонент меняет свой ход на каждом шаге\n",
    "def reactionary_agent(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        expected_opponent_actions = [0, 1, 2]\n",
    "        expected_opponent_actions.remove(observation.lastOpponentAction)\n",
    "        expected_opponent_action = expected_opponent_actions[random.randrange(0, 2)]\n",
    "        return action_to_win(expected_opponent_action)\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "\n",
    "\n",
    "# агент, играющий поочерёдно \"камень\", \"бумага\", \"ножницы\"\n",
    "seq_opponent_agent_action = None\n",
    "def sequental_agent(observation, configuration):\n",
    "    global seq_opponent_agent_action\n",
    "    if observation.step == 0:\n",
    "        seq_opponent_agent_action = random.randrange(0, configuration.signs)\n",
    "    seq_opponent_agent_action = (seq_opponent_agent_action + 1) % configuration.signs\n",
    "    return seq_opponent_agent_action\n",
    "\n",
    "\n",
    "# агент, выдающий на каждом шаге случайный ход\n",
    "def random_agent(observation, configuration):\n",
    "    return random.randrange(0, configuration.signs)\n",
    "\n",
    "\n",
    "# агент, выбирающий случайно или \"камень\", или \"бумага\"\n",
    "def rock_paper_agent(observation, configuration):\n",
    "    possible_action = random.randrange(0, 2)\n",
    "    return 0 if possible_action == 0 else 1\n",
    "\n",
    "\n",
    "# агент, выбирающий случайно или \"камень\", или \"ножницы\"\n",
    "def rock_scissors_agent(observation, configuration):\n",
    "    possible_action = random.randrange(0, 2)\n",
    "    return 0 if possible_action == 0 else 2\n",
    "\n",
    "\n",
    "# агент, выбирающий случайно или \"бумага\", или \"ножницы\"\n",
    "def paper_scissors_agent(observation, configuration):\n",
    "    possible_action = random.randrange(0, 2)\n",
    "    return 1 if possible_action == 0 else 2\n",
    "\n",
    "\n",
    "# агент, копящий статистику всех ходов оппонента, определяющий его самый частый ход\n",
    "# и выбирающий ход, чтобы победить с наибольшей вероятностью\n",
    "stat_opp_action_counts = None\n",
    "def statistical_agent(observation, configuration):\n",
    "    global stat_opp_action_counts\n",
    "    if observation.step == 0:\n",
    "        stat_opp_action_counts = [0, 0, 0]\n",
    "    if hasattr(observation, 'lastOpponentAction') and \\\n",
    "    observation.lastOpponentAction in list(range(0, configuration.signs)):\n",
    "        stat_opp_action_counts[observation.lastOpponentAction] += 1\n",
    "    frequent_opponent_action = stat_opp_action_counts.index(max(stat_opp_action_counts))\n",
    "    return action_to_win(frequent_opponent_action)\n",
    "\n",
    "\n",
    "# агент, копящий статистику последних 10 ходов оппонента, определяющий его самый частый ход\n",
    "# за эти 10 ходов и выбирающий ход, чтобы победить с наибольшей вероятностью\n",
    "react_stat_opp_actions = None\n",
    "def react_statistical_agent(observation, configuration):\n",
    "    global react_stat_opp_actions\n",
    "    if observation.step == 0:\n",
    "        react_stat_opp_actions = []\n",
    "    if hasattr(observation, 'lastOpponentAction'):\n",
    "        react_stat_opp_actions.append(observation.lastOpponentAction)\n",
    "    if (len(react_stat_opp_actions) > 10):\n",
    "        react_stat_opp_actions = react_stat_opp_actions[1:]\n",
    "    opponent_action_counts = [react_stat_opp_actions.count(action) for action in range(0, configuration.signs)]\n",
    "    frequent_opponent_action = opponent_action_counts.index(max(opponent_action_counts))\n",
    "    return action_to_win(frequent_opponent_action)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример игры между агентами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[999.0, -999.0]]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    environment=\"rps\", # выбор игровой среды \"камень, ножницы, бумага\"\n",
    "    configuration={\"episodeSteps\", 100}, #количество ходов игровых агентов\n",
    "    agents=[rock_agent, scissors_agent], #игровые агенты\n",
    "    num_episodes=1 #число эпизодов\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогон игр между различными агентами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    environment=\"rps\", # выбор игровой среды \"камень, ножницы, бумага\"\n",
    "    configuration={\"episodeSteps\", 100}, #количество ходов игровых агентов\n",
    "    agents=[statistical_agent, sequental_agent], #игровые агенты\n",
    "    num_episodes=1, #число эпизодов\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    environment=\"rps\", # выбор игровой среды \"камень, ножницы, бумага\"\n",
    "    configuration={\"episodeSteps\", 100}, #количество ходов игровых агентов\n",
    "    agents=[statistical_agent, random_agent], #игровые агенты\n",
    "    num_episodes=1, #число эпизодов\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[151.0, -151.0]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    environment=\"rps\", # выбор игровой среды \"камень, ножницы, бумага\"\n",
    "    configuration={\"episodeSteps\", 100}, #количество ходов игровых агентов\n",
    "    agents=[react_statistical_agent, statistical_agent], #игровые агенты\n",
    "    num_episodes=1, #число эпизодов\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогам прогонов игр между разными агентами наилучшие результаты показывают агенты _statistical_agent_ и _react_statistical_agent_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "147d13357d5f2dd4b74c1e03ff53873263dd4e9f6a1d41a9418dffa8cb38572d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
