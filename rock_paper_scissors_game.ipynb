{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Игра \"камень, ножницы, бумага\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U kaggle_environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек и функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kaggle_environments import make, evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ходы игроков представлены целочисленными константами:\n",
    "+ 0 - \"камень\"\n",
    "+ 1 - \"бумага\"\n",
    "+ 2 - \"ножницы\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, возвращающая ход, который нужно сделать, чтобы выиграть оппонента, на основании его предполагаемого хода *opponent_action*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_to_win(opponent_action):\n",
    "    if opponent_action == 0:\n",
    "        return 1\n",
    "    elif opponent_action == 1:\n",
    "        return 2\n",
    "    elif opponent_action == 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Атрибут *observation.lastOpponentAction* присутствует не всегда, поэтому в функциях агентов делается проверка его существования вызовом *hasattr(obj, name)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры игровых агентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# агент, выдающий всегда \"камень\"\n",
    "def rock_agent(observation, configuration):\n",
    "    return 0\n",
    "\n",
    "\n",
    "# агент, выдающий всегда \"бумага\"\n",
    "def paper_agent(observation, configuration):\n",
    "    return 1\n",
    "\n",
    "\n",
    "# агент, выдающий всегда \"ножницы\"\n",
    "def scissors_agent(observation, configuration):\n",
    "    return 2\n",
    "\n",
    "\n",
    "# агент, копирующий предыдущий ход оппонента\n",
    "def copy_agent(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        return observation.lastOpponentAction\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "\n",
    "\n",
    "# агент, предполагающий, что оппонент меняет свой ход на каждом шаге\n",
    "def reactionary_agent(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        expected_opponent_actions = [0, 1, 2]\n",
    "        expected_opponent_actions.remove(observation.lastOpponentAction)\n",
    "        expected_opponent_action = expected_opponent_actions[random.randrange(0, 2)]\n",
    "        return action_to_win(expected_opponent_action)\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "\n",
    "\n",
    "# агент, играющий поочерёдно \"камень\", \"бумага\", \"ножницы\"\n",
    "seq_opponent_agent_action = None\n",
    "def sequental_agent(observation, configuration):\n",
    "    global seq_opponent_agent_action\n",
    "    if observation.step == 0:\n",
    "        seq_opponent_agent_action = random.randrange(0, configuration.signs)\n",
    "    seq_opponent_agent_action = (seq_opponent_agent_action + 1) % configuration.signs\n",
    "    return seq_opponent_agent_action\n",
    "\n",
    "\n",
    "# агент, выдающий на каждом шаге случайный ход\n",
    "def random_agent(observation, configuration):\n",
    "    return random.randrange(0, configuration.signs)\n",
    "\n",
    "\n",
    "# агент, выбирающий случайно или \"камень\", или \"бумага\"\n",
    "def rock_paper_agent(observation, configuration):\n",
    "    possible_action = random.randrange(0, 2)\n",
    "    return 0 if possible_action == 0 else 1\n",
    "\n",
    "\n",
    "# агент, выбирающий случайно или \"камень\", или \"ножницы\"\n",
    "def rock_scissors_agent(observation, configuration):\n",
    "    possible_action = random.randrange(0, 2)\n",
    "    return 0 if possible_action == 0 else 2\n",
    "\n",
    "\n",
    "# агент, выбирающий случайно или \"бумага\", или \"ножницы\"\n",
    "def paper_scissors_agent(observation, configuration):\n",
    "    possible_action = random.randrange(0, 2)\n",
    "    return 1 if possible_action == 0 else 2\n",
    "\n",
    "\n",
    "# агент, копящий статистику всех ходов оппонента, определяющий его самый частый ход\n",
    "# и выбирающий ход, чтобы победить с наибольшей вероятностью\n",
    "stat_opp_action_counts = None\n",
    "def statistical_agent(observation, configuration):\n",
    "    global stat_opp_action_counts\n",
    "    if observation.step == 0:\n",
    "        stat_opp_action_counts = [0, 0, 0]\n",
    "    if hasattr(observation, 'lastOpponentAction') and \\\n",
    "    observation.lastOpponentAction in list(range(0, configuration.signs)):\n",
    "        stat_opp_action_counts[observation.lastOpponentAction] += 1\n",
    "    frequent_opponent_action = stat_opp_action_counts.index(max(stat_opp_action_counts))\n",
    "    return action_to_win(frequent_opponent_action)\n",
    "\n",
    "\n",
    "# агент, копящий статистику последних 10 ходов оппонента, определяющий его самый частый ход\n",
    "# за эти 10 ходов и выбирающий ход, чтобы победить с наибольшей вероятностью\n",
    "react_stat_opp_actions = None\n",
    "def react_statistical_agent(observation, configuration):\n",
    "    global react_stat_opp_actions\n",
    "    if observation.step == 0:\n",
    "        react_stat_opp_actions = []\n",
    "    if hasattr(observation, 'lastOpponentAction'):\n",
    "        react_stat_opp_actions.append(observation.lastOpponentAction)\n",
    "    if (len(react_stat_opp_actions) > 10):\n",
    "        react_stat_opp_actions = react_stat_opp_actions[1:]\n",
    "    opponent_action_counts = [react_stat_opp_actions.count(action) for action in range(0, configuration.signs)]\n",
    "    frequent_opponent_action = opponent_action_counts.index(max(opponent_action_counts))\n",
    "    return action_to_win(frequent_opponent_action)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример игры между агентами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99.0, -99.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    environment=\"rps\", #выбор игровой среды \"камень, ножницы, бумага\"\n",
    "    configuration={\"episodeSteps\": 100}, #количество ходов игровых агентов\n",
    "    agents=[rock_agent, scissors_agent], #игровые агенты\n",
    "    num_episodes=1 #число эпизодов\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогон игр между различными агентами и вывод количества очков каждого агента. Очки считаются по количеству выигрышей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENT - SCORE\n",
      "statistical - 15\n",
      "react_statistical - 14\n",
      "rock - 6\n",
      "paper - 6\n",
      "scissors - 6\n",
      "sequental - 5\n",
      "rock_paper - 3\n",
      "rock_scissors - 3\n",
      "paper_scissors - 3\n",
      "copy - 1\n",
      "reactionary - 0\n",
      "random - 0\n"
     ]
    }
   ],
   "source": [
    "env = \"rps\" #выбор игровой среды \"камень, ножницы, бумага\"\n",
    "conf = {\"episodeSteps\": 100} #количество ходов игровых агентов\n",
    "n_episodes = 1 #число эпизодов\n",
    "\n",
    "#все игровые агенты и их очки\n",
    "agents = {\n",
    "          'rock': [rock_agent, 0],\n",
    "          'paper': [paper_agent, 0],\n",
    "          'scissors': [scissors_agent, 0],\n",
    "          'copy': [copy_agent, 0],\n",
    "          'reactionary' : [reactionary_agent, 0],\n",
    "          'sequental' : [sequental_agent, 0],\n",
    "          'random' : [random_agent, 0],\n",
    "          'rock_paper' : [rock_paper_agent, 0],\n",
    "          'rock_scissors' : [rock_scissors_agent, 0],\n",
    "          'paper_scissors' : [paper_scissors_agent, 0],\n",
    "          'statistical' : [statistical_agent, 0],\n",
    "          'react_statistical' : [react_statistical_agent, 0]\n",
    "          }\n",
    "\n",
    "for agent_name, agent_inst in agents.items():\n",
    "    for opponent_name, opponent_inst in agents.items():        \n",
    "        score = evaluate(environment=env, configuration=conf,\n",
    "            agents=[agent_inst[0], opponent_inst[0]], num_episodes=n_episodes)[0]\n",
    "        agent_inst[1] += 1 if score[0] > score[1] else 0\n",
    "        opponent_inst[1] += 1 if score[1] > score[0] else 0\n",
    "\n",
    "agents_list = sorted(agents.items(), key=lambda item: item[1][1], reverse=True)\n",
    "\n",
    "print('AGENT - SCORE')\n",
    "for agent_name, agent_inst in agents_list:\n",
    "    print(agent_name, agent_inst[1], sep=' - ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогам прогонов игр между разными агентами наилучшие результаты показывают агенты *statistical_agent* и *react_statistical_agent*, наихудшие результаты - агенты *copy_agent*, *reactionary_agent* и *random_agent*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "147d13357d5f2dd4b74c1e03ff53873263dd4e9f6a1d41a9418dffa8cb38572d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
